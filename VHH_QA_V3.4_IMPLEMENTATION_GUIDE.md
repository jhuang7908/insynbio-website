# VHH QA v3.4 å®æ–½æŒ‡å—ï¼ˆCursor æŒ‡ä»¤ç‰ˆï¼‰

**æ—¥æœŸ**: 2025å¹´12æœˆ10æ—¥  
**ç›®æ ‡ç‰ˆæœ¬**: v3.4.0  
**å·¥ä½œç›®å½•**: `D:\InSynBio-AI-Research\Antibody_Engineer_Suite`

---

## æŒ‡ä»¤ 0ï¼šåˆ‡åˆ†æ”¯ï¼Œé”å®šå·¥ä½œåŒº

### æ­¥éª¤ 0.1ï¼šæ£€æŸ¥å½“å‰çŠ¶æ€

```powershell
cd D:\InSynBio-AI-Research\Antibody_Engineer_Suite
git status
```

### æ­¥éª¤ 0.2ï¼šåˆ›å»ºå¹¶åˆ‡æ¢åˆ°æ–°åˆ†æ”¯

```powershell
git checkout -b feature/vhh_qa_v3_4
```

---

## æŒ‡ä»¤ 1ï¼šæ–°å»ºæ ¡å‡†æ¨¡å— `core/vhh_qa_data_calibration.py`

### æ­¥éª¤ 1.1ï¼šåˆ›å»ºæ–‡ä»¶

åœ¨ Cursor å·¦ä¾§ Explorer ä¸­ï¼Œå®šä½åˆ° `core/` ç›®å½•ï¼Œæ–°å»ºæ–‡ä»¶ï¼š`core/vhh_qa_data_calibration.py`

### æ­¥éª¤ 1.2ï¼šå†™å…¥å®Œæ•´ä»£ç 

```python
"""
VHH QAæ•°æ®æ ¡å‡†æ¨¡å—

åŸºäºå†å²VHHæ•°æ®åº“ç»Ÿè®¡ï¼Œæ ¡å‡†QAé˜ˆå€¼å’Œæƒé‡
"""

import json
from pathlib import Path
from typing import Dict, Any, Optional, List
import numpy as np

PROJECT_ROOT = Path(__file__).resolve().parents[1]


class VHHDataCalibration:
    """
    åŸºäºå†å²VHHæ•°æ®åº“ç»Ÿè®¡ï¼Œæ ¡å‡†QAé˜ˆå€¼å’Œæƒé‡
    """
    
    def __init__(self, calibration_db_path: Optional[str] = None):
        """
        åˆå§‹åŒ–æ ¡å‡†å™¨
        
        Args:
            calibration_db_path: æ ¡å‡†æ•°æ®åº“JSONæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
                                å¦‚æœä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤å€¼æˆ–å†…ç½®é»˜è®¤æƒé‡
        """
        self.calibration_db_path = calibration_db_path
        self.db = None
        self.success_risk_median = 0.2
        self.success_risk_p75 = 0.3
        self.failed_risk_median = 0.6
        self.failed_risk_p25 = 0.5
        self.structural_risk_weight = 0.20
        self.hallmark_penalty = 0.15
        
        if calibration_db_path:
            self.db = self._load_calibration_db(calibration_db_path)
            self._compute_distributions()
        else:
            # ä½¿ç”¨é»˜è®¤å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
            self._use_default_weights()
    
    def _load_calibration_db(self, db_path: str) -> Dict[str, Any]:
        """
        åŠ è½½æ ¡å‡†æ•°æ®åº“
        
        æ•°æ®åº“ç»“æ„ï¼š
        {
            "successful_cases": [
                {
                    "structural_risk": float,
                    "has_hallmark": bool,
                    "cdr3_anchor_match": bool,
                    "final_outcome": "success"
                },
                ...
            ],
            "failed_cases": [
                {
                    "structural_risk": float,
                    "has_hallmark": bool,
                    "cdr3_anchor_match": bool,
                    "final_outcome": "failed",
                    "failure_reason": str
                },
                ...
            ]
        }
        """
        db_file = Path(db_path)
        if not db_file.exists():
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
            return {"successful_cases": [], "failed_cases": []}
        
        with open(db_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _compute_distributions(self):
        """è®¡ç®—æˆåŠŸ/å¤±è´¥æ¡ˆä¾‹çš„åˆ†å¸ƒç»Ÿè®¡"""
        if not self.db:
            self._use_default_weights()
            return
        
        # æˆåŠŸæ¡ˆä¾‹çš„structural_riskåˆ†å¸ƒ
        success_cases = self.db.get("successful_cases", [])
        if success_cases:
            success_risks = [c.get("structural_risk", 0.2) for c in success_cases]
            self.success_risk_median = float(np.median(success_risks))
            self.success_risk_p75 = float(np.percentile(success_risks, 75))
        else:
            self.success_risk_median = 0.2
            self.success_risk_p75 = 0.3
        
        # å¤±è´¥æ¡ˆä¾‹çš„structural_riskåˆ†å¸ƒ
        failed_cases = self.db.get("failed_cases", [])
        if failed_cases:
            failed_risks = [c.get("structural_risk", 0.6) for c in failed_cases]
            self.failed_risk_median = float(np.median(failed_risks))
            self.failed_risk_p25 = float(np.percentile(failed_risks, 25))
        else:
            self.failed_risk_median = 0.6
            self.failed_risk_p25 = 0.5
        
        # è®¡ç®—æ ¡å‡†æƒé‡
        self._calibrate_weights()
    
    def _calibrate_weights(self):
        """
        åŸºäºåˆ†å¸ƒå·®å¼‚æ ¡å‡†æƒé‡
        
        åŸç†ï¼š
        - å¦‚æœæˆåŠŸæ¡ˆä¾‹çš„median risk = 0.2ï¼Œå¤±è´¥æ¡ˆä¾‹çš„median risk = 0.6
        - åˆ™riskå·®å¼‚ = 0.4ï¼Œè¿™æ˜¯"æœ‰æ„ä¹‰çš„å·®å¼‚"
        - æƒé‡åº”è¯¥ä½¿å¾—è¿™ä¸ªå·®å¼‚èƒ½å¤Ÿæ˜¾è‘—å½±å“final_score
        """
        risk_diff = self.failed_risk_median - self.success_risk_median
        
        if risk_diff > 0:
            # ç›®æ ‡ï¼šä½¿å¾—riskå·®å¼‚èƒ½å¤Ÿäº§ç”Ÿè‡³å°‘0.1çš„final_scoreå·®å¼‚
            # å³ï¼šweight * risk_diff >= 0.1
            self.structural_risk_weight = max(0.1, 0.1 / risk_diff)
        else:
            self.structural_risk_weight = 0.20  # é»˜è®¤å€¼
        
        # Hallmark penaltyæ ¡å‡†
        success_cases = self.db.get("successful_cases", [])
        failed_cases = self.db.get("failed_cases", [])
        
        if success_cases and failed_cases:
            success_with_hallmark = sum(1 for c in success_cases 
                                       if c.get("has_hallmark", True))
            failed_without_hallmark = sum(1 for c in failed_cases 
                                         if not c.get("has_hallmark", True))
            
            total_success = len(success_cases)
            total_failed = len(failed_cases)
            
            hallmark_success_rate = success_with_hallmark / total_success if total_success > 0 else 0.9
            hallmark_failure_rate = failed_without_hallmark / total_failed if total_failed > 0 else 0.3
            
            # Hallmarkç¼ºå¤±çš„å¤±è´¥ç‡å·®å¼‚
            hallmark_impact = hallmark_failure_rate - (1 - hallmark_success_rate)
            self.hallmark_penalty = max(0.05, min(0.25, hallmark_impact))
        else:
            self.hallmark_penalty = 0.15  # é»˜è®¤å€¼
    
    def _use_default_weights(self):
        """ä½¿ç”¨é»˜è®¤æƒé‡ï¼ˆå½“æ²¡æœ‰æ ¡å‡†æ•°æ®æ—¶ï¼‰"""
        self.structural_risk_weight = 0.20
        self.hallmark_penalty = 0.15
    
    def get_calibrated_weights(self) -> Dict[str, float]:
        """
        è¿”å›æ ¡å‡†åçš„æƒé‡
        
        Returns:
            åŒ…å«æ ¡å‡†æƒé‡çš„å­—å…¸
        """
        return {
            "structural_risk_weight": self.structural_risk_weight,
            "hallmark_penalty": self.hallmark_penalty,
            "success_risk_median": self.success_risk_median,
            "failed_risk_median": self.failed_risk_median,
            "calibration_source": "VHH_historical_database" if self.db else "default"
        }
```

### æ­¥éª¤ 1.3ï¼šéªŒè¯å¯¼å…¥

åœ¨ç»ˆç«¯è¿è¡Œï¼š

```powershell
python -c "from core.vhh_qa_data_calibration import VHHDataCalibration; print('âœ… å¯¼å…¥æˆåŠŸ')"
```

---

## æŒ‡ä»¤ 2ï¼šæ–°å»ºåˆ†å±‚ç»“æ„é£é™©æ¨¡å— `core/vhh_qa_structural_risk_layered.py`

### æ­¥éª¤ 2.1ï¼šåˆ›å»ºæ–‡ä»¶

åœ¨ `core/` ç›®å½•ä¸‹æ–°å»ºæ–‡ä»¶ï¼š`core/vhh_qa_structural_risk_layered.py`

### æ­¥éª¤ 2.2ï¼šå†™å…¥å®Œæ•´ä»£ç 

```python
"""
VHHåˆ†å±‚ç»“æ„é£é™©è®¡ç®—æ¨¡å—

å°†ç»“æ„é£é™©åˆ†ä¸ºä¸‰ä¸ªç»´åº¦ï¼š
1. FR2 hydrophilic patchå®Œæ•´æ€§
2. Graftingåœ¨interfaceä¸Šçš„èƒ½é‡å˜åŒ–
3. CDR3 anchor residuesåŒ¹é…åº¦
"""

from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass

# IMGTåŒºåŸŸè¾¹ç•Œï¼ˆä»v3.3å¯¼å…¥ï¼‰
IMGT_REGIONS = {
    "FR1": {"start": 1, "end": 26},
    "CDR1": {"start": 27, "end": 38},
    "FR2": {"start": 39, "end": 55},
    "CDR2": {"start": 56, "end": 65},
    "FR3": {"start": 66, "end": 104},
    "CDR3": {"start": 105, "end": 117},
    "FR4": {"start": 118, "end": 128},
}

# VHH hallmarkä½ç½®ï¼ˆIMGTç¼–å·ï¼‰
VHH_HALLMARK_POSITIONS = [37, 44, 45, 47]

# CDR3 anchorä½ç½®ï¼ˆIMGTç¼–å·ï¼‰
CDR3_ANCHOR_POSITIONS = [95, 96, 101, 102]


@dataclass
class StructuralRiskComponents:
    """ç»“æ„é£é™©çš„åˆ†å±‚ç»„ä»¶"""
    fr2_hydrophilic_patch_risk: float  # 0~1, FR2 hydrophilic patchå®Œæ•´æ€§
    grafting_interface_risk: float      # 0~1, Graftingåœ¨interfaceä¸Šçš„èƒ½é‡å˜åŒ–
    cdr3_anchor_risk: float            # 0~1, CDR3 anchor residuesåŒ¹é…åº¦
    
    @property
    def total_risk(self) -> float:
        """
        åŠ æƒç»„åˆæ€»é£é™©
        
        æƒé‡ï¼š
        - FR2 risk: 0.3ï¼ˆé‡è¦ä½†å¯å®¹å¿ï¼‰
        - Grafting risk: 0.3ï¼ˆé‡è¦ä½†å¯å®¹å¿ï¼‰
        - CDR3 anchor risk: 0.4ï¼ˆç”Ÿæ­»çº¿ï¼Œæƒé‡æœ€é«˜ï¼‰
        """
        return (
            0.3 * self.fr2_hydrophilic_patch_risk +
            0.3 * self.grafting_interface_risk +
            0.4 * self.cdr3_anchor_risk
        )
    
    def to_dict(self) -> Dict[str, float]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "fr2_hydrophilic_patch_risk": self.fr2_hydrophilic_patch_risk,
            "grafting_interface_risk": self.grafting_interface_risk,
            "cdr3_anchor_risk": self.cdr3_anchor_risk,
            "total_risk": self.total_risk
        }


def compute_layered_structural_risk(
    orig_regions: Dict[str, str],
    hum_regions: Dict[str, str],
    template_info: Optional[Dict[str, Any]] = None
) -> StructuralRiskComponents:
    """
    è®¡ç®—åˆ†å±‚ç»“æ„é£é™©
    
    Args:
        orig_regions: åŸå§‹åºåˆ—åŒºåŸŸ
        hum_regions: äººæºåŒ–åºåˆ—åŒºåŸŸ
        template_info: æ¨¡æ¿ä¿¡æ¯ï¼ˆç”¨äºanchoråŒ¹é…ï¼‰
    
    Returns:
        StructuralRiskComponents
    """
    # 1. FR2 hydrophilic patché£é™©
    fr2_risk = _compute_fr2_hydrophilic_patch_risk(orig_regions, hum_regions)
    
    # 2. Grafting interfaceé£é™©
    grafting_risk = _compute_grafting_interface_risk(orig_regions, hum_regions)
    
    # 3. CDR3 anchoré£é™©ï¼ˆå…³é”®ï¼‰
    anchor_risk = _compute_cdr3_anchor_risk(orig_regions, hum_regions, template_info)
    
    return StructuralRiskComponents(
        fr2_hydrophilic_patch_risk=fr2_risk,
        grafting_interface_risk=grafting_risk,
        cdr3_anchor_risk=anchor_risk
    )


def _compute_fr2_hydrophilic_patch_risk(
    orig_regions: Dict[str, str],
    hum_regions: Dict[str, str]
) -> float:
    """
    è®¡ç®—FR2 hydrophilic patchå®Œæ•´æ€§é£é™©
    
    VHH hallmarkä½ç½®ï¼š37, 44, 45, 47
    è¿™äº›ä½ç½®å½¢æˆhydrophilic patchï¼Œå¯¹å•åŸŸæŠ˜å è‡³å…³é‡è¦
    """
    orig_fr2 = orig_regions.get("FR2", "")
    hum_fr2 = hum_regions.get("FR2", "")
    
    if not orig_fr2 or not hum_fr2:
        return 1.0  # ç¼ºå¤±FR2ï¼Œé£é™©æœ€é«˜
    
    # FR2ä»IMGT 39å¼€å§‹
    fr2_start = IMGT_REGIONS["FR2"]["start"]  # 39
    
    # æ£€æŸ¥æ¯ä¸ªhallmarkä½ç½®çš„ä¿ç•™æƒ…å†µ
    preserved_count = 0
    for pos in VHH_HALLMARK_POSITIONS:
        # è½¬æ¢ä¸ºFR2å†…çš„ç´¢å¼•ï¼ˆ0-basedï¼‰
        local_idx = pos - fr2_start
        
        if 0 <= local_idx < len(orig_fr2) and 0 <= local_idx < len(hum_fr2):
            orig_aa = orig_fr2[local_idx]
            hum_aa = hum_fr2[local_idx]
            
            # å¦‚æœä¿ç•™æˆ–å˜ä¸ºæ›´hydrophilicçš„æ®‹åŸºï¼Œç®—ä¿ç•™
            if orig_aa == hum_aa:
                preserved_count += 1
            elif _is_hydrophilic_improvement(orig_aa, hum_aa):
                preserved_count += 1
    
    # é£é™© = 1 - ä¿ç•™æ¯”ä¾‹
    risk = 1.0 - (preserved_count / len(VHH_HALLMARK_POSITIONS))
    return max(0.0, min(1.0, risk))


def _compute_grafting_interface_risk(
    orig_regions: Dict[str, str],
    hum_regions: Dict[str, str]
) -> float:
    """
    è®¡ç®—graftingåœ¨interfaceä¸Šçš„èƒ½é‡å˜åŒ–é£é™©ï¼ˆÎ”Î”G proxyï¼‰
    
    ä½¿ç”¨ç°æœ‰çš„qa_grafting_impactï¼Œä½†è½¬æ¢ä¸º0~1çš„é£é™©åˆ†æ•°
    """
    try:
        from core.vhh_qa_grafting import qa_grafting_impact
        
        _, _, impact_details = qa_grafting_impact(orig_regions, hum_regions)
        impact_normalized = impact_details.get("impact_score_normalized", 0)
        
        # å½’ä¸€åŒ–åˆ°0~1é£é™©åˆ†æ•°
        # impact_normalizedé€šå¸¸åœ¨0~1ä¹‹é—´ï¼Œä½†å¯èƒ½è¶…è¿‡1
        risk = min(1.0, impact_normalized / 0.4)  # 0.4æ˜¯erroré˜ˆå€¼
        return risk
    except ImportError:
        # å¦‚æœqa_grafting_impactä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤å€¼
        return 0.5


def _compute_cdr3_anchor_risk(
    orig_regions: Dict[str, str],
    hum_regions: Dict[str, str],
    template_info: Optional[Dict[str, Any]] = None
) -> float:
    """
    è®¡ç®—CDR3 anchor residuesåŒ¹é…åº¦é£é™©ï¼ˆç”Ÿæ­»çº¿ï¼‰
    
    CDR3 anchorä½ç½®ï¼šIMGT 95, 96, 101, 102
    è¿™äº›ä½ç½®åœ¨FR3ä¸­ï¼Œå¯¹CDR3æ„å‹è‡³å…³é‡è¦
    
    å¦‚æœæ¨¡æ¿101/102ä¸ºæŸç§ç±»å‹ï¼Œhumanizedä¹Ÿè¦ä¿æŒä¸€è‡´
    å¦åˆ™structural_risk â‰¥ 0.7 â†’ å¿…é¡»fail
    """
    orig_fr3 = orig_regions.get("FR3", "")
    hum_fr3 = hum_regions.get("FR3", "")
    
    if not orig_fr3 or not hum_fr3:
        return 1.0  # ç¼ºå¤±FR3ï¼Œé£é™©æœ€é«˜
    
    # FR3ä»IMGT 66å¼€å§‹
    fr3_start = IMGT_REGIONS["FR3"]["start"]  # 66
    
    # æ£€æŸ¥æ¯ä¸ªanchorä½ç½®çš„åŒ¹é…æƒ…å†µ
    mismatches = 0
    critical_mismatches = 0  # 101/102æ˜¯å…³é”®ä½ç½®
    
    for pos in CDR3_ANCHOR_POSITIONS:
        local_idx = pos - fr3_start
        
        if 0 <= local_idx < len(orig_fr3) and 0 <= local_idx < len(hum_fr3):
            orig_aa = orig_fr3[local_idx]
            hum_aa = hum_fr3[local_idx]
            
            if orig_aa != hum_aa:
                mismatches += 1
                # 101/102æ˜¯å…³é”®ä½ç½®
                if pos in [101, 102]:
                    critical_mismatches += 1
    
    # é£é™©è®¡ç®—
    if critical_mismatches > 0:
        # å…³é”®ä½ç½®ä¸åŒ¹é…ï¼Œé£é™©æé«˜
        risk = 0.7 + (critical_mismatches * 0.15)  # è‡³å°‘0.7ï¼Œæ¯ä¸ªå…³é”®mismatch +0.15
    else:
        # éå…³é”®ä½ç½®ä¸åŒ¹é…ï¼Œé£é™©è¾ƒä½
        risk = mismatches * 0.2  # æ¯ä¸ªmismatch +0.2
    
    # å¦‚æœæ¨¡æ¿ä¿¡æ¯å¯ç”¨ï¼Œæ£€æŸ¥æ¨¡æ¿çš„anchorç±»å‹
    if template_info:
        template_fr3 = template_info.get("fr3_sequence", "")
        if not template_fr3 and isinstance(template_info, dict):
            # å°è¯•ä»templateçš„å…¶ä»–å­—æ®µè·å–FR3
            template_regions = template_info.get("regions", {})
            template_fr3 = template_regions.get("FR3", "")
        
        if template_fr3:
            # æ£€æŸ¥101/102ä½ç½®
            for pos in [101, 102]:
                local_idx = pos - fr3_start
                if 0 <= local_idx < len(template_fr3) and 0 <= local_idx < len(hum_fr3):
                    template_aa = template_fr3[local_idx]
                    hum_aa = hum_fr3[local_idx]
                    
                    # å¦‚æœhumanizedçš„anchorä¸æ¨¡æ¿ä¸åŒ¹é…ï¼Œé£é™©æé«˜
                    if template_aa != hum_aa:
                        risk = max(risk, 0.8)
    
    return max(0.0, min(1.0, risk))


def _is_hydrophilic_improvement(orig_aa: str, hum_aa: str) -> bool:
    """
    åˆ¤æ–­æ–°æ®‹åŸºæ˜¯å¦æ¯”åŸæ®‹åŸºæ›´äº²æ°´ï¼ˆimprovementï¼‰
    
    ç®€å•çš„äº²æ°´æ€§åˆ¤æ–­ï¼š
    - äº²æ°´æ®‹åŸºï¼šD, E, K, R, H, N, Q, S, T, Y
    - ç–æ°´æ®‹åŸºï¼šA, V, L, I, M, F, W, P
    """
    hydrophilic = set("DEKRHNQSTY")
    hydrophobic = set("AVLIMFWP")
    
    orig_is_hydrophilic = orig_aa in hydrophilic
    hum_is_hydrophilic = hum_aa in hydrophilic
    
    # å¦‚æœä»ç–æ°´å˜ä¸ºäº²æ°´ï¼Œæˆ–ä¿æŒäº²æ°´ï¼Œç®—improvement
    if orig_aa in hydrophobic and hum_aa in hydrophilic:
        return True
    if orig_aa in hydrophilic and hum_aa in hydrophilic:
        return True
    
    return False
```

### æ­¥éª¤ 2.3ï¼šéªŒè¯å¯¼å…¥

```powershell
python -c "from core.vhh_qa_structural_risk_layered import compute_layered_structural_risk, StructuralRiskComponents; print('âœ… å¯¼å…¥æˆåŠŸ')"
```

---

## æŒ‡ä»¤ 3ï¼šæ–°å»º v3.4 QA éªŒè¯å…¥å£ `core/vhh_qa_validation_v3_4.py`

### æ­¥éª¤ 3.1ï¼šåˆ›å»ºæ–‡ä»¶

åœ¨ `core/` ç›®å½•ä¸‹æ–°å»ºæ–‡ä»¶ï¼š`core/vhh_qa_validation_v3_4.py`

### æ­¥éª¤ 3.2ï¼šå†™å…¥å®Œæ•´ä»£ç 

```python
"""
VHHäººæºåŒ–ç»“æœQAéªŒè¯æ¨¡å— v3.4

v3.4å‡çº§ï¼š
- åŸºäºæ•°æ®åˆ†å¸ƒæ ¡å‡†çš„æƒé‡ä½“ç³»
- åˆ†å±‚ç»“æ„é£é™©ï¼ˆFR2/grafting/CDR3 anchorï¼‰
- CDR3 anchoré£é™©ä½œä¸ºç”Ÿæ­»çº¿æ£€æŸ¥
"""

from typing import Dict, List, Any, Optional
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parents[1]

# å¯¼å…¥v3.3çš„åŸºç¡€åŠŸèƒ½ï¼ˆå¤ç”¨ï¼‰
from core.vhh_qa_validation_v3_3 import (
    validate_vhh_humanization_result_v3_3,
    _create_warning,
    auto_build_mutations_from_regions
)

# å¯¼å…¥v3.4æ–°æ¨¡å—
from core.vhh_qa_data_calibration import VHHDataCalibration
from core.vhh_qa_structural_risk_layered import (
    compute_layered_structural_risk,
    StructuralRiskComponents
)


def compute_final_score_v3_4(
    candidate: Dict[str, Any],
    calibration: Optional[VHHDataCalibration] = None
) -> float:
    """
    v3.4: ä½¿ç”¨æ ¡å‡†æƒé‡çš„final_scoreè®¡ç®—
    
    Args:
        candidate: å€™é€‰æ¨¡æ¿å­—å…¸
        calibration: æ•°æ®æ ¡å‡†å™¨ï¼ˆå¦‚æœæä¾›ï¼Œä½¿ç”¨æ ¡å‡†æƒé‡ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    
    Returns:
        final score
    """
    scores = candidate.get("alignment_scores", {}) or candidate.get("scores", {})
    base = scores.get("combined_score", 0.0) or scores.get("combined", 0.0)
    
    # è·å–structural_riskï¼ˆåº”è¯¥å·²ç»åœ¨å€™é€‰ä¸­è®¡ç®—å¹¶å†™å…¥ï¼‰
    structural_risk = scores.get("structural_risk", 0.0)
    
    # å¦‚æœè¿˜æ²¡æœ‰structural_riskï¼Œå°è¯•ä»risk_componentsè®¡ç®—
    if structural_risk == 0.0:
        risk_components = scores.get("structural_risk_components", {})
        if risk_components:
            structural_risk = risk_components.get("total_risk", 0.0)
    
    # è·å–æ ¡å‡†æƒé‡
    if calibration:
        weights = calibration.get_calibrated_weights()
        structural_risk_weight = weights["structural_risk_weight"]
        hallmark_penalty_base = weights["hallmark_penalty"]
    else:
        structural_risk_weight = 0.20
        hallmark_penalty_base = 0.15
    
    # Hallmark penalty
    actual_hallmark_penalty = 0.0
    flags = candidate.get("flags", {}) or {}
    template = candidate.get("template", {})
    if isinstance(template, dict):
        template_flags = template.get("flags", {}) or {}
        flags = {**flags, **template_flags}
    
    if not flags.get("has_vhh_hallmark", True):
        actual_hallmark_penalty = hallmark_penalty_base
    elif flags.get("reduced_hallmark", False):
        actual_hallmark_penalty = hallmark_penalty_base * 0.33
    
    final = base - structural_risk_weight * structural_risk - actual_hallmark_penalty
    
    # æ›´æ–°candidateçš„scores
    if "scores" not in candidate:
        candidate["scores"] = {}
    candidate["scores"]["final"] = final
    candidate["scores"]["structural_risk"] = structural_risk
    candidate["scores"]["structural_risk_weight"] = structural_risk_weight
    candidate["scores"]["hallmark_penalty"] = actual_hallmark_penalty
    
    return final


def validate_vhh_humanization_result_v3_4(
    result: Dict[str, Any],
    strict: bool = True,
    calibration: Optional[VHHDataCalibration] = None
) -> Dict[str, Any]:
    """
    VHHäººæºåŒ–ç»“æœQAéªŒè¯ v3.4
    
    v3.4å‡çº§ï¼š
    - åŸºäºæ•°æ®åˆ†å¸ƒæ ¡å‡†çš„æƒé‡ä½“ç³»
    - åˆ†å±‚ç»“æ„é£é™©ï¼ˆFR2/grafting/CDR3 anchorï¼‰
    - CDR3 anchoré£é™©ä½œä¸ºç”Ÿæ­»çº¿æ£€æŸ¥
    
    Args:
        result: äººæºåŒ–ç»“æœå­—å…¸
        strict: æ˜¯å¦ä¸¥æ ¼æ¨¡å¼ï¼ˆé»˜è®¤Trueï¼Œæœ‰errorå³å¤±è´¥ï¼‰
        calibration: æ•°æ®æ ¡å‡†å™¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        qa_v3_4ç»“æ„ï¼ˆå…¼å®¹v3.3æ ¼å¼ï¼Œæ–°å¢structural_risk_componentsï¼‰
    """
    # å…ˆè¿è¡Œv3.3çš„åŸºç¡€æ£€æŸ¥ï¼ˆå¤ç”¨ï¼‰
    qa_v3_3 = validate_vhh_humanization_result_v3_3(result, strict=False)
    
    errors = qa_v3_3.get("errors", [])
    warnings = qa_v3_3.get("warnings", [])
    
    # è·å–åºåˆ—åˆ†æç»“æœ
    seq_analysis = result.get("sequence_analysis", {})
    orig_regions = seq_analysis.get("original_regions", {}) or {}
    hum_regions = seq_analysis.get("humanized_regions", {}) or {}
    template_info = result.get("best_match", {}).get("template", {})
    
    # === v3.4: è®¡ç®—åˆ†å±‚ç»“æ„é£é™©ï¼ˆé¡¶å±‚ï¼‰ ===
    risk_components = compute_layered_structural_risk(
        orig_regions, hum_regions, template_info
    )
    
    # å°†risk_componentså†™å…¥result
    if "qa" not in result:
        result["qa"] = {}
    result["qa"]["structural_risk_components"] = risk_components.to_dict()
    
    # === v3.4: CDR3 anchorç”Ÿæ­»çº¿æ£€æŸ¥ ===
    if risk_components.cdr3_anchor_risk >= 0.7:
        errors.append(
            f"CDR3 anchor residuesé£é™©è¿‡é«˜ ({risk_components.cdr3_anchor_risk:.2f})ï¼Œ"
            "è¿™æ˜¯VHHæŠ˜å çš„ç”Ÿæ­»çº¿ã€‚æ¨¡æ¿101/102ä½ç½®ä¸humanizedä¸åŒ¹é…ï¼Œ"
            "å¯èƒ½å¯¼è‡´ç»“æ„ä¸ç¨³å®šæˆ–æ— æ³•æŠ˜å ã€‚"
        )
    
    # === v3.4: æ›´æ–°æ‰€æœ‰å€™é€‰æ¨¡æ¿çš„structural_risk + final_score ===
    candidates = result.get("candidates", [])
    for cand in candidates:
        # è·å–å€™é€‰æ¨¡æ¿çš„åŒºåŸŸä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾candidatesä¸­å¯èƒ½åŒ…å«orig_regionså’Œhum_regions
        # å¦‚æœæ²¡æœ‰ï¼Œä½¿ç”¨å…¨å±€çš„orig_regionså’Œhum_regions
        cand_orig_regions = cand.get("orig_regions", orig_regions)
        cand_hum_regions = cand.get("hum_regions", hum_regions)
        
        # å¦‚æœcandidatesä¸­æ²¡æœ‰å•ç‹¬çš„åŒºåŸŸä¿¡æ¯ï¼Œä½¿ç”¨å…¨å±€çš„
        if not cand_orig_regions or not cand_hum_regions:
            cand_orig_regions = orig_regions
            cand_hum_regions = hum_regions
        
        # è®¡ç®—å€™é€‰æ¨¡æ¿çš„åˆ†å±‚ç»“æ„é£é™©
        cand_risk_components = compute_layered_structural_risk(
            cand_orig_regions, cand_hum_regions, cand.get("template", {})
        )
        
        # æ›´æ–°candidateçš„scores
        if "scores" not in cand:
            cand["scores"] = {}
        cand["scores"]["structural_risk_components"] = cand_risk_components.to_dict()
        cand["scores"]["structural_risk"] = cand_risk_components.total_risk
        
        # ä½¿ç”¨æ ¡å‡†æƒé‡è®¡ç®—final_score
        compute_final_score_v3_4(cand, calibration)
    
    # === æ„å»ºqa_v3_4ç»“æœï¼ˆå…¼å®¹v3.3æ ¼å¼ï¼‰ ===
    qa_v3_4 = {
        "ok": len(errors) == 0,
        "errors": errors,
        "warnings": warnings,
        "checks": qa_v3_3.get("checks", {}),
        "summary_score": qa_v3_3.get("summary_score", {}),
        "structural_risk_components": risk_components.to_dict(),  # v3.4æ–°å¢
        "meta": {
            "version": "3.4.0",
            "ruleset": "VHH_QA_V3.4_CALIBRATED",
            "calibration_used": calibration is not None
        }
    }
    
    # å¦‚æœv3.3æœ‰å…¶ä»–å­—æ®µï¼Œä¹Ÿä¿ç•™
    for key in ["mutation_map", "conformation_risk_summary", "experimental_recommendations"]:
        if key in qa_v3_3:
            qa_v3_4[key] = qa_v3_3[key]
    
    return qa_v3_4
```

### æ­¥éª¤ 3.3ï¼šéªŒè¯å¯¼å…¥

```powershell
python -c "from core.vhh_qa_validation_v3_4 import validate_vhh_humanization_result_v3_4, compute_final_score_v3_4; print('âœ… å¯¼å…¥æˆåŠŸ')"
```

---

## æŒ‡ä»¤ 4ï¼šåœ¨ç°æœ‰VHH pipelineä¸­æŒ‚ä¸Šv3.4

### æ­¥éª¤ 4.1ï¼šæ‰¾åˆ°ä¸»å…¥å£æ–‡ä»¶

æ£€æŸ¥ `core/vhh_humanization_with_qa.py`ï¼Œæ‰¾åˆ°QAéªŒè¯çš„è°ƒç”¨ä½ç½®ã€‚

### æ­¥éª¤ 4.2ï¼šæ›´æ–° `core/vhh_humanization_with_qa.py`

åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥ï¼š

```python
from core.vhh_qa_validation_v3_4 import validate_vhh_humanization_result_v3_4
from core.vhh_qa_data_calibration import VHHDataCalibration
```

æ‰¾åˆ° `humanize_vhh_with_qa` å‡½æ•°ä¸­è°ƒç”¨QAéªŒè¯çš„ä½ç½®ï¼ˆå¤§çº¦åœ¨ç¬¬74-75è¡Œï¼‰ï¼Œä¿®æ”¹ä¸ºï¼š

```python
# QAéªŒè¯ - ä½¿ç”¨v3.4ï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
qa_v3_4_result = validate_vhh_humanization_result_v3_4(json_data, strict=strict_qa)

# åŒæ—¶è¿è¡Œv3.3ä»¥ä¿æŒå…¼å®¹æ€§
from core.vhh_qa_validation_v3_3 import validate_vhh_humanization_result_v3_3
qa_v3_3_result = validate_vhh_humanization_result_v3_3(json_data, strict=strict_qa)

# åŒæ—¶è¿è¡Œv3.2ä»¥ä¿æŒå…¼å®¹æ€§
from core.vhh_qa_validation import validate_vhh_humanization_result_v3
qa_v3_result = validate_vhh_humanization_result_v3(json_data, strict=strict_qa)

# ç»Ÿä¸€æ¥å£ç»“æ„ï¼šresult["qa"]["v3_4"] = qa_v3_4ï¼ˆæœ€æ–°ï¼‰
# åŒæ—¶ä¿æŒv2/v3å…¼å®¹æ€§
qa_v2_result = validate_vhh_humanization_result(json_data, strict=False)

result["qa"] = {
    "v2": qa_v2_result,  # v2.0ç»“æœ
    "v3": qa_v3_result,  # v3.2ç»“æœï¼ˆå…¼å®¹ï¼‰
    "v3_3": qa_v3_3_result,  # v3.3ç»“æœï¼ˆå…¼å®¹ï¼‰
    "v3_4": qa_v3_4_result  # v3.4ç»“æœï¼ˆæœ€æ–°ï¼‰
}

# å‘åå…¼å®¹ï¼šç›´æ¥è®¿é—®result["qa"]æ—¶è¿”å›v3.4ç»“æœï¼ˆæœ€æ–°ç‰ˆæœ¬ï¼‰
result["qa"]["ok"] = qa_v3_4_result.get("ok", False)
result["qa"]["errors"] = qa_v3_4_result.get("errors", [])
# v3.4çš„warningsè½¬æ¢ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨ä»¥ä¿æŒå…¼å®¹
warnings_list = []
for w in qa_v3_4_result.get("warnings", []):
    if isinstance(w, dict):
        warnings_list.append(w.get("message", str(w)))
    else:
        warnings_list.append(str(w))
result["qa"]["warnings"] = warnings_list
```

æ›´æ–°QAé€šè¿‡åˆ¤æ–­ï¼š

```python
# QAé€šè¿‡ï¼ˆä½¿ç”¨v3.4ç»“æœï¼‰
if qa_v3_4_result["ok"]:
    result["status"] = "OK"
    v3_4_warnings = qa_v3_4_result.get("warnings", [])
    if v3_4_warnings:
        major_warnings = [w for w in v3_4_warnings if isinstance(w, dict) and w.get("level") == "major"]
        if major_warnings:
            logger.warning(f"QAä¸»è¦è­¦å‘Š: {[w.get('message') for w in major_warnings]}")
    return result

# QAä¸é€šè¿‡
logger.warning(f"æ ‡å‡†æ¨¡å¼QAéªŒè¯å¤±è´¥: {qa_v3_4_result['errors']}")
```

æ›´æ–°statusï¼š

```python
# æ‰€æœ‰æ¨¡å¼éƒ½å¤±è´¥
result["status"] = "FAILED_QA_V3_4"
```

---

## æŒ‡ä»¤ 5ï¼šå¿«é€Ÿæœ¬åœ°éªŒè¯ï¼ˆä¸ä¾èµ–çœŸå®DBå…ˆè·‘é€šï¼‰

### æ­¥éª¤ 5.1ï¼šåˆ›å»ºæµ‹è¯•è„šæœ¬

æ–°å»ºæ–‡ä»¶ï¼š`tests/manual_test_vhh_qa_v3_4.py`

```python
"""
æ‰‹åŠ¨æµ‹è¯•VHH QA v3.4ï¼ˆä¸ä¾èµ–çœŸå®æ•°æ®åº“ï¼‰
"""

from core.vhh_qa_validation_v3_4 import validate_vhh_humanization_result_v3_4
from core.vhh_qa_data_calibration import VHHDataCalibration


def make_minimal_result_skeleton():
    """æ„é€ æœ€å°åŒ–æµ‹è¯•æ•°æ®"""
    return {
        "sequence_analysis": {
            "original_regions": {
                "FR1": "EVQLVESGGGLVQPGGSLRLSCAAS",
                "CDR1": "GFNIKDTY",
                "FR2": "MHWVRQRPGKGLEWVSA",
                "CDR2": "YISYSGST",
                "FR3": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC",
                "CDR3": "AAGGVGWPYFDY",
                "FR4": "WGQGTQVTVSS"
            },
            "humanized_regions": {
                "FR1": "EVQLVESGGGLVQPGGSLRLSCAAS",
                "CDR1": "GFNIKDTY",
                "FR2": "MHWVRQRPGKGLEWVSA",
                "CDR2": "YISYSGST",
                "FR3": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC",
                "CDR3": "AAGGVGWPYFDY",
                "FR4": "WGQGTQVTVSS"
            }
        },
        "best_match": {
            "humanized_sequence": "EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYMHWVRQRPGKGLEWVSAYISYSGSTYYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYCAAGGVGWPYFDYWGQGTQVTVSS",
            "template": {
                "id": "TEMPLATE_001",
                "flags": {"has_vhh_hallmark": True},
                "fr3_sequence": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC"
            },
            "developability": {"score": 0.65, "score_type": "aggregate"},
            "immunogenicity": {"fr_immuno_risk": "low"}
        },
        "original_developability": {"score": 0.60},
        "original_immunogenicity": {"fr_immuno_risk": "low"},
        "candidates": [
            {
                "template_id": "HUMAN_VH3_SCF_24",
                "scores": {
                    "fr_identity": 0.82,
                    "combined": 0.70
                },
                "flags": {"has_vhh_hallmark": True},
                "template": {
                    "id": "HUMAN_VH3_SCF_24",
                    "flags": {"has_vhh_hallmark": True},
                    "fr3_sequence": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC"
                }
            }
        ],
        "mutations": {"list": []}
    }


def main():
    print("=" * 80)
    print("VHH QA v3.4 æ‰‹åŠ¨æµ‹è¯•")
    print("=" * 80)
    
    # æ„é€ æµ‹è¯•æ•°æ®
    dummy_result = make_minimal_result_skeleton()
    
    # æµ‹è¯•1ï¼šä¸ä½¿ç”¨æ ¡å‡†ï¼ˆé»˜è®¤æƒé‡ï¼‰
    print("\næµ‹è¯•1: ä¸ä½¿ç”¨æ ¡å‡†ï¼ˆé»˜è®¤æƒé‡ï¼‰")
    out1 = validate_vhh_humanization_result_v3_4(dummy_result, strict=True, calibration=None)
    print(f"âœ… OK: {out1['ok']}")
    print(f"ğŸ“Š Structural Risk Components: {out1.get('structural_risk_components', {})}")
    print(f"âŒ Errors: {len(out1.get('errors', []))}")
    print(f"âš ï¸  Warnings: {len(out1.get('warnings', []))}")
    
    # æµ‹è¯•2ï¼šä½¿ç”¨é»˜è®¤æ ¡å‡†å™¨ï¼ˆæ— æ•°æ®åº“ï¼‰
    print("\næµ‹è¯•2: ä½¿ç”¨é»˜è®¤æ ¡å‡†å™¨ï¼ˆæ— æ•°æ®åº“ï¼‰")
    calibration = VHHDataCalibration(calibration_db_path=None)
    out2 = validate_vhh_humanization_result_v3_4(dummy_result, strict=True, calibration=calibration)
    print(f"âœ… OK: {out2['ok']}")
    print(f"ğŸ“Š Calibrated Weights: {calibration.get_calibrated_weights()}")
    
    # æµ‹è¯•3ï¼šCDR3 anchoré«˜é£é™©åœºæ™¯
    print("\næµ‹è¯•3: CDR3 anchoré«˜é£é™©åœºæ™¯")
    high_risk_result = make_minimal_result_skeleton()
    # ä¿®æ”¹FR3çš„101/102ä½ç½®ï¼Œä½¿å…¶ä¸åŒ¹é…
    fr3_list = list(high_risk_result["sequence_analysis"]["humanized_regions"]["FR3"])
    # FR3ä»IMGT 66å¼€å§‹ï¼Œ101-66=35, 102-66=36
    if len(fr3_list) > 36:
        fr3_list[35] = "X"  # 101ä½ç½®
        fr3_list[36] = "Y"  # 102ä½ç½®
    high_risk_result["sequence_analysis"]["humanized_regions"]["FR3"] = "".join(fr3_list)
    out3 = validate_vhh_humanization_result_v3_4(high_risk_result, strict=True, calibration=None)
    print(f"âœ… OK: {out3['ok']}")
    print(f"ğŸ“Š CDR3 Anchor Risk: {out3.get('structural_risk_components', {}).get('cdr3_anchor_risk', 0):.2f}")
    print(f"âŒ Errors: {out3.get('errors', [])}")
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()
```

### æ­¥éª¤ 5.2ï¼šè¿è¡Œæµ‹è¯•

```powershell
python -m tests.manual_test_vhh_qa_v3_4
```

**é¢„æœŸè¾“å‡º**:
- æ²¡æœ‰å¼‚å¸¸æŠ¥é”™
- è¾“å‡ºä¸­åŒ…å« `structural_risk_components` å­—å…¸
- errors/warnings ç»“æ„æ­£å¸¸
- æµ‹è¯•3åº”è¯¥æ£€æµ‹åˆ°CDR3 anchoré«˜é£é™©å¹¶äº§ç”Ÿerror

---

## æŒ‡ä»¤ 6ï¼šæ•´ç†å•å…ƒæµ‹è¯• + æäº¤ä»£ç 

### æ­¥éª¤ 6.1ï¼šåˆ›å»ºå•å…ƒæµ‹è¯•æ–‡ä»¶

æ–°å»ºæ–‡ä»¶ï¼š`tests/test_vhh_qa_v3_4.py`

```python
"""
VHH QA v3.4 å•å…ƒæµ‹è¯•
"""

import pytest
from core.vhh_qa_validation_v3_4 import (
    validate_vhh_humanization_result_v3_4,
    compute_final_score_v3_4
)
from core.vhh_qa_data_calibration import VHHDataCalibration
from core.vhh_qa_structural_risk_layered import (
    compute_layered_structural_risk,
    StructuralRiskComponents
)


def make_minimal_result_skeleton():
    """æ„é€ æœ€å°åŒ–æµ‹è¯•æ•°æ®éª¨æ¶"""
    return {
        "sequence_analysis": {
            "original_regions": {
                "FR1": "EVQLVESGGGLVQPGGSLRLSCAAS",
                "CDR1": "GFNIKDTY",
                "FR2": "MHWVRQRPGKGLEWVSA",
                "CDR2": "YISYSGST",
                "FR3": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC",
                "CDR3": "AAGGVGWPYFDY",
                "FR4": "WGQGTQVTVSS"
            },
            "humanized_regions": {
                "FR1": "EVQLVESGGGLVQPGGSLRLSCAAS",
                "CDR1": "GFNIKDTY",
                "FR2": "MHWVRQRPGKGLEWVSA",
                "CDR2": "YISYSGST",
                "FR3": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC",
                "CDR3": "AAGGVGWPYFDY",
                "FR4": "WGQGTQVTVSS"
            }
        },
        "best_match": {
            "humanized_sequence": "EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYMHWVRQRPGKGLEWVSAYISYSGSTYYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYCAAGGVGWPYFDYWGQGTQVTVSS",
            "template": {
                "id": "TEMPLATE_001",
                "flags": {"has_vhh_hallmark": True},
                "fr3_sequence": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC"
            },
            "developability": {"score": 0.65, "score_type": "aggregate"},
            "immunogenicity": {"fr_immuno_risk": "low"}
        },
        "original_developability": {"score": 0.60},
        "original_immunogenicity": {"fr_immuno_risk": "low"},
        "candidates": [],
        "mutations": {"list": []}
    }


def test_cdr3_anchor_risk_high_should_fail():
    """æµ‹è¯•ï¼šCDR3 anchoré£é™© >= 0.7 æ—¶åº”è¯¥fail"""
    result = make_minimal_result_skeleton()
    
    # ä¿®æ”¹FR3çš„101/102ä½ç½®ï¼Œä½¿å…¶ä¸åŒ¹é…ï¼ˆé«˜é£é™©ï¼‰
    fr3_list = list(result["sequence_analysis"]["humanized_regions"]["FR3"])
    # FR3ä»IMGT 66å¼€å§‹ï¼Œ101-66=35, 102-66=36
    if len(fr3_list) > 36:
        fr3_list[35] = "X"  # 101ä½ç½®
        fr3_list[36] = "Y"  # 102ä½ç½®
    result["sequence_analysis"]["humanized_regions"]["FR3"] = "".join(fr3_list)
    
    qa_v3_4 = validate_vhh_humanization_result_v3_4(result, strict=True)
    
    assert qa_v3_4["ok"] is False, "CDR3 anchoré£é™©>=0.7åº”è¯¥fail"
    assert len(qa_v3_4["errors"]) > 0, "åº”è¯¥æœ‰error"
    assert any("CDR3 anchor" in e for e in qa_v3_4["errors"]), "åº”è¯¥æœ‰CDR3 anchorç›¸å…³çš„error"


def test_hallmark_penalty_applied():
    """æµ‹è¯•ï¼šhallmarkç¼ºå¤±æ—¶hallmark_penaltyæ­£å¸¸ç”Ÿæ•ˆ"""
    candidate = {
        "scores": {
            "combined": 0.70,
            "structural_risk": 0.3
        },
        "flags": {"has_vhh_hallmark": False},
        "template": {"flags": {}}
    }
    
    final_score = compute_final_score_v3_4(candidate, calibration=None)
    
    # åº”è¯¥åº”ç”¨hallmark_penalty (0.15)
    expected_final = 0.70 - 0.20 * 0.3 - 0.15
    assert abs(final_score - expected_final) < 0.01, f"Final scoreåº”è¯¥è€ƒè™‘hallmark penalty: {final_score} vs {expected_final}"


def test_calibration_weights_applied():
    """æµ‹è¯•ï¼šæä¾›calibrationæ—¶ï¼Œstructural_risk_weightåº”è¯¥å˜åŒ–"""
    candidate = {
        "scores": {
            "combined": 0.70,
            "structural_risk": 0.3
        },
        "flags": {"has_vhh_hallmark": True},
        "template": {"flags": {}}
    }
    
    # ä¸ä½¿ç”¨æ ¡å‡†
    final_score_default = compute_final_score_v3_4(candidate, calibration=None)
    
    # ä½¿ç”¨æ ¡å‡†ï¼ˆé»˜è®¤æ ¡å‡†å™¨ï¼Œæ— æ•°æ®åº“ï¼Œåº”è¯¥ä½¿ç”¨é»˜è®¤æƒé‡ï¼‰
    calibration = VHHDataCalibration(calibration_db_path=None)
    final_score_calibrated = compute_final_score_v3_4(candidate, calibration=calibration)
    
    # é»˜è®¤æ ¡å‡†å™¨åº”è¯¥ä½¿ç”¨é»˜è®¤æƒé‡ï¼Œæ‰€ä»¥ç»“æœåº”è¯¥ç›¸åŒ
    assert abs(final_score_default - final_score_calibrated) < 0.01, "é»˜è®¤æ ¡å‡†åº”è¯¥ä½¿ç”¨é»˜è®¤æƒé‡"


def test_layered_structural_risk_components():
    """æµ‹è¯•ï¼šåˆ†å±‚ç»“æ„é£é™©ç»„ä»¶è®¡ç®—"""
    orig_regions = {
        "FR2": "MHWVRQRPGKGLEWVSA",
        "FR3": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC"
    }
    hum_regions = {
        "FR2": "MHWVRQRPGKGLEWVSA",
        "FR3": "YYADSVKGRFTISRDNSKNTLYLQMGSLRAEDMAVYYC"
    }
    
    risk_components = compute_layered_structural_risk(orig_regions, hum_regions)
    
    assert isinstance(risk_components, StructuralRiskComponents)
    assert 0 <= risk_components.fr2_hydrophilic_patch_risk <= 1
    assert 0 <= risk_components.grafting_interface_risk <= 1
    assert 0 <= risk_components.cdr3_anchor_risk <= 1
    assert 0 <= risk_components.total_risk <= 1
    assert "total_risk" in risk_components.to_dict()


def test_structural_risk_components_in_result():
    """æµ‹è¯•ï¼šç»“æœä¸­åº”è¯¥åŒ…å«structural_risk_components"""
    result = make_minimal_result_skeleton()
    
    qa_v3_4 = validate_vhh_humanization_result_v3_4(result, strict=True)
    
    assert "structural_risk_components" in qa_v3_4, "åº”è¯¥åŒ…å«structural_risk_components"
    components = qa_v3_4["structural_risk_components"]
    assert "fr2_hydrophilic_patch_risk" in components
    assert "grafting_interface_risk" in components
    assert "cdr3_anchor_risk" in components
    assert "total_risk" in components
```

### æ­¥éª¤ 6.2ï¼šè¿è¡Œæµ‹è¯•

```powershell
python -m pytest tests/test_vhh_qa_v3_4.py -v
```

### æ­¥éª¤ 6.3ï¼šæäº¤ä»£ç 

```powershell
git status
git add core/vhh_qa_data_calibration.py
git add core/vhh_qa_structural_risk_layered.py
git add core/vhh_qa_validation_v3_4.py
git add tests/manual_test_vhh_qa_v3_4.py
git add tests/test_vhh_qa_v3_4.py
git add core/vhh_humanization_with_qa.py
git commit -m "Add VHH QA v3.4 with layered structural risk and calibrated scoring"
```

---

## æŒ‡ä»¤ 7ï¼šé¢„ç•™ v3.5 çš„æ‰©å±•ä½

### æ­¥éª¤ 7.1ï¼šåœ¨ `core/vhh_qa_validation_v3_4.py` åº•éƒ¨æ·»åŠ TODO

```python
# TODO(v3.5):
# - å¼•å…¥ ranking stability æ¨¡å— (analyze_ranking_stability, calibrate_score_consistency)
# - åœ¨ validate_vhh_humanization_result_v3_4 ä¸­è¿½åŠ  ranking sanity éƒ¨åˆ†
# - ä½¿ç”¨ç›¸å¯¹æ’åºç¨³å®šæ€§æ¨¡å‹æ›¿ä»£heuristicé˜ˆå€¼
# - å®ç°pairwise consistencyæ£€æŸ¥
# - é›†æˆisotonic regressionæ ¡å‡†
```

---

## éªŒè¯æ¸…å•

å®Œæˆæ‰€æœ‰æ­¥éª¤åï¼Œè¿è¡Œä»¥ä¸‹éªŒè¯ï¼š

```powershell
# 1. æ£€æŸ¥æ‰€æœ‰æ–°æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls core/vhh_qa_data_calibration.py
ls core/vhh_qa_structural_risk_layered.py
ls core/vhh_qa_validation_v3_4.py
ls tests/test_vhh_qa_v3_4.py

# 2. è¿è¡Œå•å…ƒæµ‹è¯•
python -m pytest tests/test_vhh_qa_v3_4.py -v

# 3. è¿è¡Œæ‰‹åŠ¨æµ‹è¯•
python -m tests.manual_test_vhh_qa_v3_4

# 4. æ£€æŸ¥å¯¼å…¥
python -c "from core.vhh_qa_validation_v3_4 import validate_vhh_humanization_result_v3_4; print('âœ… v3.4å¯¼å…¥æˆåŠŸ')"
```

---

## æ–‡ä»¶ç»“æ„æ€»ç»“

```
core/
â”œâ”€â”€ vhh_qa_data_calibration.py          # æ–°å¢ï¼šæ•°æ®æ ¡å‡†æ¨¡å—
â”œâ”€â”€ vhh_qa_structural_risk_layered.py   # æ–°å¢ï¼šåˆ†å±‚ç»“æ„é£é™©
â”œâ”€â”€ vhh_qa_validation_v3_4.py          # æ–°å¢ï¼šv3.4 QAéªŒè¯å…¥å£
â””â”€â”€ vhh_humanization_with_qa.py         # ä¿®æ”¹ï¼šé›†æˆv3.4

tests/
â”œâ”€â”€ manual_test_vhh_qa_v3_4.py          # æ–°å¢ï¼šæ‰‹åŠ¨æµ‹è¯•è„šæœ¬
â””â”€â”€ test_vhh_qa_v3_4.py                 # æ–°å¢ï¼šå•å…ƒæµ‹è¯•
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2025å¹´12æœˆ10æ—¥

















